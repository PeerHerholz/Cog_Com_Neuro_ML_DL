{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b855ba9e",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "We will start with the boring but very important mathematical background that you will need to better understand the machine learning models.\n",
    "\n",
    "Let's start with the general introduction of scalars, vectors and matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb252b2",
   "metadata": {},
   "source": [
    "## Elements of linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5dbaa",
   "metadata": {},
   "source": [
    "### Scalar, Vectors, Matrices, Tensors\n",
    "\n",
    "The basic objects which we will use throughout this sessions are shown below:\n",
    "\n",
    "![alt text](../../../static/linear_algebra/svmt_0.png)\n",
    "\n",
    "- **Scalar**: A scalar is just a single number. Variables assigned to scalars are usually lowercase letters. When they are introduced, the space in which they live is usually also indicated, e.g., $a \\in \\mathbb{R}$. This means that $a$ can take any value of the real number space.\n",
    "\n",
    "\n",
    "\n",
    "- **Vectors**: A vector is defined as an array of numbers. In standard Python you would represent a vector as a list of values. Vectors are usually defined with bold lowercase variables, e.g., $\\mathbf{x}$. The order of elments in a vector matters and is defined. The first element of the vector $\\mathbf{x}$ is $x_1$. As this is a scalar, we again use simple lower case variables. The dimensions and number space also has to be defined for a vector. For example $\\mathbf{x} \\in \\mathbb{R}^n$ would indicate that all values in $\\mathbf{x}$ are real and the vector has $n$ elements. <br>  You can think of a vector as identifying a point in a scace. Each element gives the coordinate along a different axis.\n",
    "\n",
    "\n",
    "- **Matrices**: Matrices are 2D-arrays of numbers. We will use bold uppercase variables to define matrices, e.g., $\\mathbf{X}$. If a matrix with only real values has $m$ rows and $n$ colums we would define it as $\\mathbf{X} \\in \\mathbb{R}^{mxn}$. In the above example both, $m$ and $n$ are two. Single elemeents within a matrix are indexed in the order of the dimensions. The first element on the upper left would be $A_{1,1}$, and the last element on the bottom right is  $A_{m,n}$.\n",
    "\n",
    "\n",
    "- **Tensors**: A tensor is a multidimensional object with several axes. The elements of a tensor $\\mathbf{A}$ with three axes would be denoted as $A_{i, j, k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7981f62",
   "metadata": {},
   "source": [
    "![alt text](../../../static/linear_algebra/svmt_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e5484",
   "metadata": {},
   "source": [
    "### Representation in programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbfe64",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "\n",
    "When computing linear algebra operations in *Python* (which is the language we are predominantly going to use), it is common to use the `Numpy`-package. This package is used as a numerical base for many other frameworks and is implicitly imported when using other modules, such as `pandas`, `tensorflow`, and many other data science related libraries. `Numpy` includes capabilities to generate linear algebra objects and complete mathematical operations with them at a faster speed than *Python* would normally allow for, since `Numpy` operations are implemented in *C*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a951f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9a9f0",
   "metadata": {},
   "source": [
    "#### Arrays\n",
    "\n",
    "An array is a data object in which scalars, vectors, matrices and tensors are stored for calculations, following a one-size-fits-all approach. To find out what kind of object is contained in an array, it is very helpful to examine its `.shape`-property. This gives you not only the amount of axis this object spans across, but also the amount of entries per axis. The `.shape` of an object plays a vital role when performing calculations with arrays, since they will indicate whether two arrays are \"compatible\" with each other.\n",
    "\n",
    "In order to define arrays in *Numpy*, think of every level of rectangular brackets as opening up a new axis.\n",
    "\n",
    "Note: `Numpy`-arrays are not to be confused with the data structure *Array* used in other programming languages, such as Java and Javascript, which does not serve any specific mathematical purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6f49e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a_array: (1,)\n",
      "Shape of b_array: (2, 1)\n",
      "Shape of c_array: (2, 2)\n",
      "Shape of d_array: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define arrays\n",
    "## Scalar\n",
    "a_array = np.array([1])\n",
    "## Vector \n",
    "b_array = np.array([[1],\n",
    "                    [2]])\n",
    "## Matrix\n",
    "c_array = np.array([[1,2],\n",
    "                    [3,4]])\n",
    "## Tensor\n",
    "d_array = np.array([[[1,9],\n",
    "                     [2,6]],\n",
    "                    [[3,8],\n",
    "                     [4,7]]])\n",
    "# Check shapes of arrays\n",
    "print(\"Shape of a_array:\", a_array.shape)\n",
    "print(\"Shape of b_array:\", b_array.shape)\n",
    "print(\"Shape of c_array:\", c_array.shape)\n",
    "print(\"Shape of d_array:\", d_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa72809",
   "metadata": {},
   "source": [
    "**Try it youself:**\n",
    "\n",
    "Define `Numpy`-arrays with the dimensions (3,); (1,3); (3,3,3) and print their shape to check for correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02488fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array with the dimensions (3,)\n",
    "a_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Array with the dimensions (1,3)\n",
    "b_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Array with the dimensions (3,3)\n",
    "c_array = ...\n",
    "# Check the array's shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a0cc8",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "\n",
    "Transpose is an important operation for matrices, as it represents the mirror image of the matrix along a diagonal line called the **main diagonal**. The transpose of a matrix $\\mathbf{X}$ would be denoted as $\\mathbf{X}^T$ and is defined such that\n",
    "$$(\\mathbf{X}^T)_{i,j} = X_j,i $$\n",
    "\n",
    "Vectors can also be thought of as matrices that only contain one column. Hence, when a (column) vector is transposed, the result is a matrix with only one row, or a (row) vector.\n",
    "\n",
    "![alt text](../../../static/linear_algebra/transpose.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6808f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector: (2, 1) Shape of matrix: (3, 2)\n",
      "Shape of vector: (1, 2) Shape of matrix: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define arrays\n",
    "a_array = np.array([[1],\n",
    "                    [2]])\n",
    "b_array = np.array([[1,2],\n",
    "                    [3,4],\n",
    "                    [5,6]])\n",
    "print(\"Shape of vector:\", a_array.shape, \"Shape of matrix:\", b_array.shape)\n",
    "# Transpose arrays\n",
    "a_transposed_array = np.transpose(a_array) # standard method\n",
    "b_transposed_array = b_array.T             # shorthand method\n",
    "print(\"Shape of vector:\", a_transposed_array.shape, \"Shape of matrix:\", b_transposed_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883deb1",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "\n",
    "`Numpy` allows you to rearrange the elements of an array to a different (congruent) shape, while retaining the order of the elements and length of the array. This can be a useful tool when you have data stored in an array which does not yet have the shape required to pass through a certain operation or algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a99c2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector: (8,)\n",
      "Shape of reshaped vector: (2, 4)\n",
      "Shape of reshaped vector: (2, 2, 2)\n",
      "Shape of reshaped vector: (8,)\n",
      "[1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# Define arrays\n",
    "a_array = np.array([1,2,3,4,5,6,7,8])\n",
    "print(\"Shape of vector:\", a_array.shape)\n",
    "# Reshape array\n",
    "a_reshaped_array = a_array.reshape((2,4))\n",
    "print(\"Shape of reshaped vector:\", a_reshaped_array.shape)\n",
    "# Reshape array again\n",
    "a_reshaped2_array = a_reshaped_array.reshape((2,2,2))\n",
    "print(\"Shape of reshaped vector:\", a_reshaped2_array.shape)\n",
    "# Reshape back to original shape and check the elements' order\n",
    "a_orig_array = a_reshaped2_array.reshape((8,))\n",
    "print(\"Shape of reshaped vector:\", a_orig_array.shape)\n",
    "print(a_orig_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e53564",
   "metadata": {},
   "source": [
    "**Try it yourself:**\n",
    "\n",
    "Define a `Numpy`-vector of length 12 and shape (12,) (e.g. using the `np.arange`-function -> `np.arange(0,12,1)`). Then create a new vector with two axes by reshaping the original vector. Afterwards, create a third vector with three axes by reshaping the previous vector. Finally, transform the past array back to the original shape and print it to check for the correct order of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66270498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an array of length 12 and shape (12,)\n",
    "a_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Rearange the original array to an array with two axes\n",
    "b_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Rearange the previous array to an array with three axes\n",
    "c_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Rearange the last array to an array with the original shape\n",
    "d_array = ...\n",
    "# Check the array's shape\n",
    "\n",
    "# Print the array itself to check for the elements' order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e487c6",
   "metadata": {},
   "source": [
    "## Mathematical operations with matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2219b",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f5809",
   "metadata": {},
   "source": [
    "A scalar can be easily added to a matrix, just by adding the scalar to each element of the matrix: $a + X = C$, where $C_{i, j} = a + X_{i, j}$.\n",
    "\n",
    "\n",
    "![alt text](../../../static/linear_algebra/addition_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469e7da",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Matrices can be easily added, as long as they have the same shape. Therefore, their corresponding elements are added: $\\mathbf{X} + \\mathbf{A} = \\mathbf{C}$, where $C_{i, j} = X_{i, j} + A_{i, j}$.\n",
    "\n",
    "![alt text](../../../static/linear_algebra/addition_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6d200",
   "metadata": {},
   "source": [
    "In deep learning it is also possible to add a vector to a matrix. In this case the vector is simply repeated so that it can be added to each row of the matrix: $\\mathbf{C} = \\mathbf{X} + \\mathbf{a}$, where $C_{i, j} = X_{i, j} + b_j$.  This concept is called **broadcasting**.\n",
    "\n",
    "Note: the subtraction of matrices is analogous to their addition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6309d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      " [[3 4]\n",
      " [5 6]]\n",
      "Result 2:\n",
      " [[ 7  8]\n",
      " [ 9 10]]\n"
     ]
    }
   ],
   "source": [
    "# Addition of an scalar to an matrix\n",
    "a_array = np.array([2])\n",
    "b_array = np.array([[1,2],\n",
    "                    [3,4]])\n",
    "c_array = a_array + b_array\n",
    "print(\"Result 1:\\n\", c_array)\n",
    "\n",
    "# Addition of matrices\n",
    "d_array = np.array([[5,6],\n",
    "                    [7,8]])\n",
    "e_array = a_array + d_array\n",
    "print(\"Result 2:\\n\",  e_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae647f",
   "metadata": {},
   "source": [
    "### Multiplication\n",
    "\n",
    "#### Dot Product\n",
    "\n",
    "Two vectors can be multiplied using the so called dot product between those two. This is a bit more advanced than the addition, as not each element of the vectors are multiplied with each other. It is denoted as:\n",
    "\n",
    "$$x^Ty = \\sum_i x_iy_i$$\n",
    "\n",
    "Hence, the vectors are multiplied element-wise and in the end all results are summed. This also implies that the dot product can only be calculated if the vectors have the same length. \n",
    "\n",
    "![alt text](../../../static/linear_algebra/multi_0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9922c6",
   "metadata": {},
   "source": [
    "Vector multiplications are `distributive`:\n",
    "\n",
    "$$ x^T (y + z) = x^Ty + x^Tz $$\n",
    "\n",
    "\n",
    "And they are `commutative`:\n",
    "\n",
    "$$ x^T y = y^Tx $$\n",
    "\n",
    "But the dot product is not `assocciative`, as $(x^Ty)z$ is the dot product between a scalar and a vector, which is not defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd8c4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a_array: (2, 1) ; Shape of b_array: (2, 1)\n",
      "Shape of a_array: (1, 2) ; Shape of b_array: (2, 1)\n",
      "Shape of resulting array: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product of two matrices\n",
    "a_array = np.array([[1],\n",
    "                    [2]])\n",
    "b_array = np.array([[3],\n",
    "                    [4]])\n",
    "# Print the arrays' shapes\n",
    "print(\"Shape of a_array:\", a_array.shape, \"; Shape of b_array:\", b_array.shape,)\n",
    "# Calculate dot product by transposing \n",
    "c_array = np.dot(a_array.T, b_array)\n",
    "# Print the arrays' shapes within the operation\n",
    "print(\"Shape of a_array:\", a_array.T.shape, \"; Shape of b_array:\", b_array.shape,)\n",
    "# Print out the resulting array and its shape\n",
    "print(\"Shape of resulting array:\", c_array.shape)\n",
    "c_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d624800b",
   "metadata": {},
   "source": [
    "**Try it yourself:**\n",
    "    \n",
    "If the arrays are commutative in the dot product operation, does it also not matter if the latter array is transposed instead of the former? Does the operation go through? What shape does the result have? Does it differ from the result obtained in the operation above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11dd7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a_array: (2, 1) ; Shape of b_array: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dot product of two matrices\n",
    "a_array = np.array([[1],\n",
    "                    [2]])\n",
    "b_array = np.array([[3],\n",
    "                    [4]])\n",
    "# Print the arrays' shapes\n",
    "print(\"Shape of a_array:\", a_array.shape, \"; Shape of b_array:\", b_array.shape,)\n",
    "# Calculate dot product by transposing \n",
    "c_array = ...\n",
    "# Print the arrays' shapes within the operation\n",
    "\n",
    "# Print out the resulting array and its shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc89764",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication\n",
    "\n",
    "The matrix mulitplication is an operation that is performed regularly in machine or deep learning. The **matrix product** of two matrices ($\\mathbf{X}$ and $\\mathbf{A}$) is again a matrix ($\\mathbf{C}$). \n",
    "\n",
    "$$ \\mathbf{C} = \\mathbf{X} \\mathbf{A}$$\n",
    "\n",
    "A matrix multiplication is only allowed if the shapes of the matrices to be multiplied matches. In this case, the matrix $\\mathbf{X}$ needs to have the same amount of columns as the number of rows in matrix $\\mathbf{A}$. If $\\mathbf{X}$ has the shape $n x m$ and $\\mathbf{A}$ is of shape $m x p$, then the dimensions of the resulting matrix $\\mathbf{C}$ are $n x p$. \n",
    "\n",
    "For each element in $\\mathbf{C}$, the matrix product can be written as:\n",
    "\n",
    "$$ C_{i, j} = \\sum_k X_{i, k}A_{k, j}$$\n",
    "\n",
    "Visually this can be represented as follows\n",
    "\n",
    "![alt text](../../../static/linear_algebra/multi_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6132535",
   "metadata": {},
   "source": [
    "Matrix multiplications are `distributive`:\n",
    "\n",
    "$$ \\mathbf{A} (\\mathbf{B} + \\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}$$\n",
    "\n",
    "They are also `assocciative`:\n",
    "\n",
    "$$ \\mathbf{A} (\\mathbf{B}\\mathbf{C}) = (\\mathbf{A}\\mathbf{B})\\mathbf{C} $$\n",
    "\n",
    "However, it is **not** `commutative`:\n",
    "\n",
    "$$ \\mathbf{A}\\mathbf{B} \\neq \\mathbf{B}\\mathbf{A} $$\n",
    "\n",
    "Note, that some special cases are commutative, however not generally.\n",
    "\n",
    "The transpose of a matrix product can be represented as:\n",
    "$$ (\\mathbf{A}\\mathbf{B})^T = \\mathbf{B}^T\\mathbf{A}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b0dde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes check: (3, 2) ; (2, 3)\n",
      "Resulting shape: (3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19, 22, 25],\n",
       "       [43, 50, 57],\n",
       "       [67, 78, 89]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "a_array = np.array([[1,2],\n",
    "                    [3,4],\n",
    "                    [5,6]])\n",
    "b_array = np.array([[5,6,7],\n",
    "                    [7,8,9]])\n",
    "# Check the shapes for alignment\n",
    "print(\"Shapes check:\", a_array.shape, \";\", b_array.shape)\n",
    "# Calcualte matrix multiplication\n",
    "c_array = np.matmul(a_array, b_array)\n",
    "# Output the resulting array and its shape\n",
    "print(\"Resulting shape:\", c_array.shape)\n",
    "c_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f56829",
   "metadata": {},
   "source": [
    "**Try it yourself:**\n",
    "\n",
    "Below find a series of arrays pairs, which are to be matrix multiplied. Check their shapes and reshape them if neccesary to make them compatible with the matrix multiplication operation. Try to predict the resulting shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fcafb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a)\n",
    "# Create two arrays\n",
    "a_array = np.array([[1,2,3,4,5,6],\n",
    "                    [7,8,9,10,11,12]])\n",
    "b_array = np.array([[1,2],\n",
    "                    [3,4],\n",
    "                    [5,6]])\n",
    "# Check shapes for compatibility\n",
    "\n",
    "# Reshape if neccesary\n",
    "\n",
    "# Compute the matrix multiplication operation\n",
    "c_array = ...\n",
    "# Output the resulting shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5212f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## b)\n",
    "# Create two arrays\n",
    "a_array = np.array([[1,2,3,4],\n",
    "                    [5,6,7,8],\n",
    "                    [9,10,11,12],\n",
    "                    [13,14,15,16]])\n",
    "b_array = np.array([[1],\n",
    "                    [2],\n",
    "                    [3],\n",
    "                    [4],\n",
    "                    [5],\n",
    "                    [6],\n",
    "                    [7],\n",
    "                    [8]])\n",
    "# Check shapes for compatibility\n",
    "\n",
    "# Reshape if neccesary\n",
    "\n",
    "# Compute the matrix multiplication operation\n",
    "c_array = ...\n",
    "# Output the resulting shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1253e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## c)\n",
    "# Create two arrays\n",
    "a_array = np.array([[[1,2],\n",
    "                     [3,4]],\n",
    "                    [[5,6],\n",
    "                     [7,8]],\n",
    "                    [[9,10],\n",
    "                     [11,12]]])\n",
    "b_array = np.array([[1,2],\n",
    "                    [3,4]])\n",
    "# Check shapes for compatibility\n",
    "\n",
    "# Reshape if neccesary\n",
    "\n",
    "# Compute the matrix multiplication operation\n",
    "c_array = ...\n",
    "# Output the resulting shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd864b1d",
   "metadata": {},
   "source": [
    "## Linear equations\n",
    "\n",
    "Now that we know how to do matrix multiplication, we can use this to write down a simple linear equatiton. Assume we have $N$ observations of variable x that has $m$ features. Take as an example different features of appartments such as flat size, year it was built, and so on. We can store this information in a matrix $X$ that has the dimensions ($N$, $m$) i.e., $X \\in \\mathbb{R}^{Nxm}$. If we now want to determine the prize for a given flat, we could use different scaling factors for each feature. Hence in an additional vector $w$ we store how much each feature affects the prize. To now calculate the prize $p$ we can write: \n",
    "$$ \\mathbf{Xw} = \\mathbf{p} $$\n",
    "\n",
    "More explicitly this would mean:\n",
    "\n",
    "$$ X_{1, 1}w_1 + X_{1, 2}w_2 + ... + X_{1, m}w_m = b_1$$\n",
    "$$ X_{2, 1}w_1 + X_{2, 2}w_2 + ... + X_{2, m}w_m = b_2$$\n",
    "\n",
    "We can also rewrite this as:\n",
    "\n",
    "$$ \\mathbf{Xw}  = \\sum_i w_i \\mathbf{X_{:,i}} = \\mathbf{p}$$\n",
    "\n",
    "where $\\mathbf{X_{:,i}}$ denotes that we perform this operation across all rows while varying the column with index $i$. This is also called a $linear combination$.\n",
    "\n",
    "This representation is especially important for deep learning including any form of linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969daeb7",
   "metadata": {},
   "source": [
    "### Linear dependence\n",
    "\n",
    "A vector is linearly dependent on a set of vectors, if the vector can be represented with a linear combination of this set of vectors. On the other hand, a set of vectors are linearly independent if no vector is a linear combination of any other vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56b5d8",
   "metadata": {},
   "source": [
    "## Matrix Inversion\n",
    "\n",
    "It is not possible to directly divide by a matrix. However, we can utilize the concept of matrix inversion to be able to solve a linear system of equations as the one above for $w$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fbe32",
   "metadata": {},
   "source": [
    "### Identity matrix\n",
    "\n",
    "For matrix inversioon we first need to define the concept of the identity matrix. The identitty matrix is denoted as $\\mathbf{I_n} \\in \\mathbb{R}^{nxn}$. This special matrix contains only ones on its diagonal. All other entries are zero. \n",
    "\n",
    "<img src=\"../../../static/linear_algebra/identity.png\" alt=\"Identity\" style=\"width: 100px;\"/>\n",
    "\n",
    "Multiplying any vector with this matrix does not change the vector. \n",
    "$$\\forall x \\in \\mathbb{R} ^n, \\mathbf{I_n x} = \\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dddd1e",
   "metadata": {},
   "source": [
    "### Matrix inverse\n",
    "\n",
    "Now we can define the matrix inverse of a given matrix $X$ as $X^{-1}$ such that\n",
    "\n",
    "$$\\mathbf{X^{-1}X} = \\mathbf{I_n}$$\n",
    "\n",
    "\n",
    "However, for $\\mathbf{X^{-1}}$ to exist $\\mathbf{X}$ has to be a square matrix (number of rows = number of columns), all columns must be linearly independent, hence the determinant, to which we will come later, has to be non-zero. \n",
    "\n",
    "Defining the matrix inverse now also allows us to solve the above defined linear system of equations for $w$. \n",
    "\n",
    "$$\\mathbf{Xw} = \\mathbf{b} $$\n",
    "$$\\mathbf{X^{-1}Xw} = \\mathbf{X^{-1}b} $$\n",
    "$$\\mathbf{I_nw} = \\mathbf{X^{-1}b} $$\n",
    "$$\\mathbf{w} = \\mathbf{X^{-1}b} $$\n",
    "\n",
    "Note, that calculating the inverse can often times be computatioonally inefficient and contain limited precision on a computer. Hence this representation is usually only for theoretical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53e30d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2. ,  1. ],\n",
       "       [ 1.5, -0.5]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define array\n",
    "a_array = np.array([[1,2],\n",
    "                    [3,4]])\n",
    "# Calculate matrix inverse\n",
    "a_inverse_array = np.linalg.inv(a_array)\n",
    "a_inverse_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2863ee1",
   "metadata": {},
   "source": [
    "## Norms\n",
    "\n",
    "We can measure the size (or length) of a vector with the help of the `norm`. It measures the distance from the origin to the point defined by the vector. \n",
    "\n",
    "Generally the $L^p$ norm is defined as\n",
    "\n",
    "$$ ||\\mathbf{x}||_p = \\left(\\sum_i |x_i|^p\\right)^{\\frac{1}{p}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "000cfef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.123105625617661"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define array\n",
    "a_array = np.array([[1],\n",
    "                    [4]])\n",
    "# Calculate matrix inverse\n",
    "a_normed_array = np.linalg.norm(a_array)\n",
    "a_normed_array"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
