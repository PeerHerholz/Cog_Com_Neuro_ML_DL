{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for neuroimaging data - [NiBabel](https://nipy.org/nibabel/)\n",
    "\n",
    "The primary goal of this section is to become familiar with `loading`, `modifying`, `saving`, and `visualizing` `neuroimages` in `Python`. A secondary goal is to develop a conceptual understanding of the `data structures` involved, to facilitate diagnosing problems in `data` or `analysis` `pipelines`.\n",
    "\n",
    "To these ends, we'll be exploring the core `python library` for `handling` and `wrangling` `neuroimaging` `data`: [nibabel](). While this short introduction should get you started, it is well worth your time to look through `nibabel's` excellent [documentation](http://nipy.org/nibabel/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Nibabel](https://nipy.org/nibabel/)\n",
    "\n",
    "![](https://nipy.org/nibabel/_static/nibabel-logo.svg)\n",
    "\n",
    "\n",
    "`Nibabel` is a low-level `Python library` that gives access to a variety of `imaging` `formats`, with a particular focus on providing a common interface to the various **volumetric** formats produced by `MRI scanners` and used in common `neuroimaging` toolkits such as [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/), [AFNI](https://afni.nimh.nih.gov/), [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/) and [SPM](https://www.fil.ion.ucl.ac.uk/spm/):\n",
    "\n",
    " - `NIfTI-1`\n",
    " - `NIfTI-2`\n",
    " - `SPM Analyze`\n",
    " - `FreeSurfer` `.mgh`/`.mgz` files\n",
    " - Philips `PAR/REC`\n",
    " - Siemens `ECAT`\n",
    " - `DICOM` (limited support)\n",
    "\n",
    "It also supports **surface** file formats:\n",
    "\n",
    " - `GIFTI`\n",
    " - `FreeSurfer` `surfaces`, `labels` and `annotations`\n",
    "\n",
    "and others such as:\n",
    "\n",
    "**Connectivity**\n",
    "\n",
    " - `CIFTI-2`\n",
    "\n",
    "**Tractography**\n",
    "\n",
    " - `TrackViz` `.trk` files\n",
    "\n",
    "as well as a number of related `formats`.\n",
    "\n",
    "**Note:** Almost all of these can be `loaded` through the [nibabel.load](https://nipy.org/nibabel/reference/nibabel.loadsave.html#nibabel.loadsave.load) `interface`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we actually start, we are going to need to `import` the `nibabel` `library` and a few others, more or less related to `basic computing` and `plotting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import nibabel as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's get started.\n",
    "\n",
    "## Loading and inspecting images in `nibabel`\n",
    "\n",
    "At first, we are going to explore how we can `load` and `inspect` `neuroimages` in `nibabel`. To this end, we will use parts of the `tutorial datasets` you should've [downloaded during the course setup](https://peerherholz.github.io/Cog_Com_Neuro_ML_DL/setup.html#getting-the-course-content). Specifically, we are going to have a closer look at a `functional MRI` of `sub-01`. As mentioned before, basically all `file formats` are accessible via the `nibabel load` `interface`. All we need to do is to provide the `path` to the file we want to `load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nb.load('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all it takes and with that, we can directly inspect our now `loaded` `fMRI` `image`, for example via `print` which will give is the information stored in the `header` of the `image`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (64, 64, 30, 184)\n",
      "affine: \n",
      "[[-3.99471426e+00 -2.04233140e-01  2.29353290e-02  1.30641693e+02]\n",
      " [-2.05448717e-01  3.98260689e+00 -3.10890853e-01 -9.74732285e+01]\n",
      " [ 6.95819734e-03  3.11659902e-01  3.98780894e+00 -8.06465759e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b'?TR:2500.000 TE:50'\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  4  64  64  30 184   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int16\n",
      "bitpix          : 16\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        4.        4.        3.999975  2.5       1.        1.\n",
      "  1.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 255\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.025633048\n",
      "quatern_c       : -0.9989105\n",
      "quatern_d       : -0.03895198\n",
      "qoffset_x       : 130.6417\n",
      "qoffset_y       : -97.47323\n",
      "qoffset_z       : -80.646576\n",
      "srow_x          : [-3.9947143e+00 -2.0423314e-01  2.2935329e-02  1.3064169e+02]\n",
      "srow_y          : [ -0.20544872   3.982607    -0.31089085 -97.47323   ]\n",
      "srow_z          : [ 6.9581973e-03  3.1165990e-01  3.9878089e+00 -8.0646576e+01]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `data-affine-header structure` is common to `volumetric` `formats` in `nibabel`, though the details of the `header` will vary from `format` to `format`. As you can see above, the here utilized example entails `information` about the `data shape`, `dimensions`, `affine`, `meta-data` and much more. All of them are very useful and good to know (and should be identical to values indicated the corresponding [json sidecar file](https://bids-specification.readthedocs.io/en/stable/02-common-principles.html#keyvalue-files-dictionaries) if you use [BIDS](https://bids.neuroimaging.io/)). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    ":class: dropdown\n",
    "\n",
    "Please have a look at each of the `field`s displayed above and try to answer the following questions: \n",
    "  * what does the `value` refer to?\n",
    "  * what does the respective `information` represent?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing specific parameters\n",
    "\n",
    "Seeing all these `parameters` entailed in the `header` we might want to evaluate and utilize some of them during various points of our `analysis pipeline`. With `nibabel` we can easily access all of them, either directly, e.g. the `affine`: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.99471426e+00, -2.04233140e-01,  2.29353290e-02,\n",
       "         1.30641693e+02],\n",
       "       [-2.05448717e-01,  3.98260689e+00, -3.10890853e-01,\n",
       "        -9.74732285e+01],\n",
       "       [ 6.95819734e-03,  3.11659902e-01,  3.98780894e+00,\n",
       "        -8.06465759e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine = img.affine\n",
    "affine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or through the `header` `object`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.      ,  4.      ,  4.      ,  3.999975,  2.5     ,  1.      ,\n",
       "        1.      ,  1.      ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = img.header['pixdim']\n",
    "header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Note\n",
    "Note that in the `'pixdim'` above contains the voxel resolution  (`4., 4., 3.999`), as well as the TR (`2.5`).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can also access the underlying `data` of the `image`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 30, 184)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = img.get_fdata()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on working with neuroimaging and memory allocation\n",
    "\n",
    "Why not just directly access the `data` via `img.data`? Working with `neuroimages` can use a lot of `memory`, so `nibabel` works hard to be `memory efficient`. If it can read some `data` while leaving the rest on `disk`, it will. `img.get_data()` reflects that it's doing exactly that via some work behind the scenes.\n",
    "\n",
    "Lets dive a bit further into this:\n",
    "\n",
    " - `img.get_data_dtype()` shows the `type` of the `data` on `disk`\n",
    " - `img.get_data().dtype` shows the `type` of the `data` that you're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dtype('<i2'), dtype('<i2'))\n"
     ]
    }
   ],
   "source": [
    "print((data.dtype, img.get_data_dtype()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though true here, these are not always the same, and not being clear on this [has caused problems](https://github.com/nipy/nibabel/issues/490). Further, modifying one does not update the other. This is especially important to keep in mind later when saving `files`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's actually in the `neuroimaging` `data`?\n",
    "\n",
    "It might sound less crazy/fancy than you thought/hoped for but the `data` is a simple `numpy` `array`. It has a `shape`, it can be `sliced` and generally manipulated as you would any `array` as it contains `numerical values` in certain `dimensions` with certain expressions. Lets use `matplotlib` to visualize the `data` after directly accessing it via `numpy` to make this more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 30, 184)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[:, :, data.shape[2] // 2, 0].T, cmap='Greys_r')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    ":class: dropdown\n",
    "\n",
    "Think about what the `data` and the respective `values` represents in terms of the discussed `MRI` principles and the signal we obtain through it. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Practical exercise 1:\n",
    "\n",
    "How about some small practical exercise to further familiarize yourself with `nibabel` and `neuroimaging` `data` handling?\n",
    "\n",
    "Please load the `T1w` `data` from `subject 1` and then `plot` the `image` using the same `volume` `indexing` as before. Also, please `print` the `shape` of the `data`. Don't worry if get stuck: just give it your best try and if it doesn't work out, have a look at the solution below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solution\n",
    ":class: dropdown\n",
    "\n",
    "    t1 = nb.load('/data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')\n",
    "    data = t1.get_data()\n",
    "    plt.imshow(data[:, :, data.shape[2] // 2].T, cmap='Greys_r')\n",
    "    print(data.shape)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually inspecting `images` via `orthoview()`\n",
    "\n",
    "`Nibabel` has its own `viewer`, which can be accessed through **`img.orthoview()`** where `img` is the `image` you `loaded` via e.g. `.load`. It should present you with either `3` or `4` `subplots` for the respective `dimensions`, ie. `3` `spatial` (`x`, `y`, `z`) and in case of `fMRI` `images` `1` `temporal`(`time` indicated via `TR`). This `viewer` `scales` `voxels` to reflect their `size`, and `label` orientations. \n",
    "\n",
    "**Warning:** `img.orthoview()` may not work properly on OS X.\n",
    "\n",
    "#### Sidenote on plotting with `orthoview()`\n",
    "As with other figures, f you initiated `matplotlib` with `%matplotlib inline`, the output figure will be static. If you use `orthoview()` in a normal `IPython console`, it will create an `interactive` window, and you can click to select different slices, similar to `mricron` or comparable viewers. To get a similar experience in a `jupyter notebook`, use `%matplotlib notebook`. But don't forget to close `figures` afterward again or use `%matplotlib inline` again, otherwise, you cannot `plot` any other `figures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='229b7254-a54a-4846-b224-ee7ce29faa28'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<OrthoSlicer3D: /data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz (64, 64, 30, 184)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "img.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we got a broad and general overview of `neuroimaging data` and what it entails, we should spend a bit more time on more precise aspects of `neuroimaging` `data` and its handling using `nibabel`. Specifically, we will spend a closer look at the `header` and the `affine`. **Please note** that we will be using the `t1w` `data` of `sub-01` for this part. Thus, if you didn't went through the `previous` `exercise`, you should do so now or make sure to check/run the solution. To make sure everything works, please try to use `.orthoview()` to `plot` and `investigate` the `t1w` `image`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solution\n",
    ":class: dropdown\n",
    "\n",
    "    t1.orthoview()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header\n",
    "\n",
    "The `header` is a general property of `neuroimaging data` in most `file formats` and in `nibabel` the structure that stores all of the `metadata` of the `image`. As indicated above, you can query it directly, if necessary. For example, getting the `description`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(b'FSL5.0', dtype='|S80')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.header['descrip']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it also provides `interfaces` for the more common information, such as `get_zooms`, `get_xyzt_units`, `get_qform`, `get_sform` which respectively provide `spatial`, `temporal` and `affine` `information` of the `image` at hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.2993759, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.header.get_zooms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mm', 'sec')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.header.get_xyzt_units()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99131938e-01, -5.16292391e-02,  1.25136054e-02,\n",
       "        -1.25263863e+02],\n",
       "       [ 4.07721521e-02,  1.29202043e+00, -9.81179047e-02,\n",
       "        -7.31330109e+01],\n",
       "       [-8.54416425e-03,  1.28044319e-01,  9.95096119e-01,\n",
       "        -1.77554291e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.header.get_qform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99131918e-01, -5.16291820e-02,  1.25127016e-02,\n",
       "        -1.25263863e+02],\n",
       "       [ 4.07721959e-02,  1.29202044e+00, -9.81179178e-02,\n",
       "        -7.31330109e+01],\n",
       "       [-8.54506902e-03,  1.28044292e-01,  9.95096147e-01,\n",
       "        -1.77554291e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.header.get_sform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of the `affine`, lets check it out in more detail:\n",
    "\n",
    "### Affine\n",
    "\n",
    "In our case, the `affine` refers to a `4 x 4 numpy array`. This describes the `transformation` from the `voxel space` (`indices` `[i, j, k]`) to the `reference space` (`distance` in `mm` `(x, y, z)`).\n",
    "\n",
    "It can be used, for instance, to discover the `voxel` that contains the `origin` of the `image`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine:\n",
      "[[-3.99471426e+00 -2.04233140e-01  2.29353290e-02  1.30641693e+02]\n",
      " [-2.05448717e-01  3.98260689e+00 -3.10890853e-01 -9.74732285e+01]\n",
      " [ 6.95819734e-03  3.11659902e-01  3.98780894e+00 -8.06465759e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Center: (31, 27, 18)\n"
     ]
    }
   ],
   "source": [
    "x, y, z, _ = np.linalg.pinv(affine).dot(np.array([0, 0, 0, 1])).astype(int)\n",
    "\n",
    "print(\"Affine:\")\n",
    "print(affine)\n",
    "print\n",
    "print(\"Center: ({:d}, {:d}, {:d})\".format(x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `affine` also encodes the `axis` `orientation` and `voxel sizes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('L', 'A', 'S')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.aff2axcodes(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.99999995, 4.00000009, 3.99997491])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.affines.voxel_sizes(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('L', 'A', 'S')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.aff2axcodes(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.99999995, 4.00000009, 3.99997491])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.affines.voxel_sizes(affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we're not particularly interested in the `header` or the `affine`. But it's important to know they're there. And especially, to remember to copy them when making new `images` or working with `derivatives`, so that they stay aligned with the original `image` (if required).\n",
    "\n",
    "Now you might think: it seems a bit cumbersome to get/access all that information to e.g. check and/or evaluate a given `image`. First of all: come on, it's just a few lines of rather simple code. Second, if you really don't want to fire up a `python` session and run a few commands/functions: `nibabel` also has your back here.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nib-ls`\n",
    "\n",
    "`Nibabel` comes packaged with a `command-line tool` called [nib-lis](https://nipy.org/nibabel/reference/nibabel.cmdline.html?highlight=nib%20ls#module-nibabel.cmdline.ls) to `print` `common` `metadata` about any (`volumetric`) `neuroimaging` `format` `nibabel` supports. By default, it shows (**`on-disk`**) `data type`, `dimensions` and `voxel sizes`. Lets try it out via using the `fMRI` `data` of `sub-01` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz int16 [ 64,  64,  30, 184] 4.00x4.00x4.00x2.50   sform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nib-ls /data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect `header` `fields` by name, for instance, `descrip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz float32 [256, 156, 256] 1.00x1.30x1.00   b'FSL5.0' sform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nib-ls -H descrip /data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the basic `neuroimaging data` exploration section which discussed `commands` and `functions` should already allow you to do a lot of common tasks and work with `neuroimaging data`. However, there's obviously way more to it. For example, `creating` and `saving` `images`.\n",
    "\n",
    "## Creating and saving images\n",
    "\n",
    "Suppose we want to save `space` by `rescaling` our `image` to a smaller `datatype`, such as an `unsigned byte`. To do this, we first need to take the `data`, change its `datatype` and `save` this new `data` in a new `NIfTI image` with the **same** `header` and `affine` as the `original image`. At first, we need to `load` the `image` and `get` the `data` (using the `fMRI` `data` of `sub-01` once more):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nb.load('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')\n",
    "data = img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we force the `values` to be between `0` and `255` and `change` the `datatype` to `unsigned 8-bit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rescaled = ((data - data.min()) * 255. / (data.max() - data.min())).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can `save` the changed `data` into a new `NIfTI file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = nb.Nifti1Image(rescaled, affine=img.affine, header=img.header)\n",
    "nb.save(new_img, 'rescaled_image.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `datatypes` of the `data array`, as well as of the `nifti image`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dtype('float64'), dtype('<i2'))\n"
     ]
    }
   ],
   "source": [
    "print((new_img.get_fdata().dtype, new_img.get_data_dtype()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not optimal. Our `data array` has the correct `type`, but the `on-disk format` is determined by the `header`, so `saving` it with `img.header` will not do what we want. Also, let's take a look at the `size` of the `original` and `new` `file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12M\trescaled_image.nii.gz\n",
      " 24M\t/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "orig_filename = img.get_filename()\n",
    "!du -hL rescaled_image.nii.gz $orig_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's correct the `header` issue with the `set_data_dtype()` `function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.set_data_dtype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then saving `image` again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = nb.Nifti1Image(rescaled, affine=img.affine, header=img.header)\n",
    "nb.save(new_img, 'rescaled_image.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which we evaluate our `image` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dtype('float64'), dtype('uint8'))\n"
     ]
    }
   ],
   "source": [
    "print((new_img.get_fdata().dtype, new_img.get_data_dtype()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now the `data` `types` are correct. And if we look at the `size` of the `image` we even see that it got a bit smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10M\trescaled_image.nii.gz\n"
     ]
    }
   ],
   "source": [
    "!du -hL rescaled_image.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this first introduction of how to work with `neuroimaging data` using `python`, we've explored `load`ing, `saving` and `visualizing` `neuroimages` via `nibabel`, as well as how it can make some more sophisticated manipulations easy. At this point, you should be able to `inspect` and `plot` most `images` you encounter, as well as make modifications while preserving the `alignment` (at least for basic operations)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.0 ('neuro_ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa3294e16c73365073ee846a76e7d53b5b9e5a293a3115a87882950862aae9bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
